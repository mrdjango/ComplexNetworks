{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PGQVO_Fzhd3r",
        "outputId": "29cae073-aa11-4256-d02e-75ab4145276f"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# @title Libraries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TUDataset\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "# @title Libraries\n",
        "import torch\n",
        "import os\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as functional\n",
        "from torch_geometric.nn import GCNConv,GraphConv,GAT\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUjKT3GCzrqO"
      },
      "source": [
        "## Creating Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HMt1UupKib4x",
        "outputId": "8976dab0-8165-4572-8cb4-c49d9f25da16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "dataset = TUDataset(root='data/', name='MUTAG')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SBlUGOjFkHM-",
        "outputId": "8813f2de-8b56-449d-8725-c46ee6b3597f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# graphs: 188\n",
            "# features: 7\n",
            "# classes: 2\n"
          ]
        }
      ],
      "source": [
        "print(f'# graphs: {len(dataset)}')\n",
        "print(f'# features: {dataset.num_features}')\n",
        "print(f'# classes: {dataset.num_classes}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "x4mu0WWPkMKR"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.shuffle()\n",
        "train, test = dataset[:140], dataset[140:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Bj8x5JRdm6Gr"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train, batch_size=50, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=50, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc3ig2UNzehq"
      },
      "source": [
        "## Creating Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8ZEtp9hAk0SA"
      },
      "outputs": [],
      "source": [
        "class MyModel(torch.nn.Module):\n",
        "  def __init__(self, hidden_channels,conv1,conv2,conv3):\n",
        "    super(MyModel, self).__init__()\n",
        "    torch.manual_seed(2024)\n",
        "    self.conv1 = conv1\n",
        "    self.conv2 = conv2\n",
        "    self.conv3 = conv3\n",
        "    self.lin = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    # 1. Obtain node embeddings\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = x.relu()\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = x.relu()\n",
        "    x = self.conv3(x, edge_index)\n",
        "    # 2. Readout layer\n",
        "    x = global_mean_pool(x, batch) # [batch_size, hidden_channels]\n",
        "    # 3. Apply a final classifier\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = self.lin(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JHFPp8hJmVKo"
      },
      "outputs": [],
      "source": [
        "class ModelHandler():\n",
        "  def __init__(self, model, epochs, learning_rate=0.01):\n",
        "    self.model = model\n",
        "    self.epochs = epochs\n",
        "    self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "    self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "  def train(self, loader):\n",
        "    with tqdm(range(self.epochs), unit='epoch') as tepochs:\n",
        "      tepochs.set_description('Training')\n",
        "      for epoch in tepochs:\n",
        "        self.model.train()\n",
        "        for data in loader: # Iterate in batches over the training dataset.\n",
        "          out = self.model(data.x, data.edge_index, data.batch) # Perform a single forward pass.\n",
        "          loss = self.criterion(out, data.y) # Compute the loss.\n",
        "          loss.backward() # Derive gradients.\n",
        "          self.optimizer.step() # Update parameters based on gradients.\n",
        "          self.optimizer.zero_grad() # Clear gradients.\n",
        "\n",
        "\n",
        "  def test(self, loader):\n",
        "    self.model.eval()\n",
        "    correct = 0\n",
        "    for data in loader: # Iterate in batches over the training/test dataset.\n",
        "      out = self.model(data.x, data.edge_index, data.batch)\n",
        "      pred = out.argmax(dim=1) # Use the class with highest probability.\n",
        "      correct += int((pred == data.y).sum()) # Check against ground-truth labels\n",
        "    return correct / len(loader.dataset) # Derive ratio of correct predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfyUnZDSxYYr"
      },
      "source": [
        "## Using GCNConv Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kPjcvNcrnxeE",
        "outputId": "a89a9f88-7347-4162-8fb3-4dff2c037c35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MyModel(\n",
            "  (conv1): GCNConv(7, 64)\n",
            "  (conv2): GCNConv(64, 64)\n",
            "  (conv3): GCNConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 170/170 [00:07<00:00, 23.50epoch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "0.8142857142857143\n",
            "0.6666666666666666\n"
          ]
        }
      ],
      "source": [
        "model = MyModel(hidden_channels=64,\n",
        "                conv1=GCNConv(dataset.num_node_features, 64),\n",
        "                conv2=GCNConv(64, 64),\n",
        "                conv3=GCNConv(64, 64))\n",
        "print(model)\n",
        "\n",
        "handler = ModelHandler(model, 170)\n",
        "\n",
        "handler.train(train_loader)\n",
        "print('\\n')\n",
        "print(handler.test(train_loader))\n",
        "print(handler.test(test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8S95UkaxeH7"
      },
      "source": [
        "## Using GraphConv Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9zdEX-QGrKPG",
        "outputId": "8cb25682-0f4b-4521-ea62-b368b8e4a8ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MyModel(\n",
            "  (conv1): GraphConv(7, 64)\n",
            "  (conv2): GraphConv(64, 64)\n",
            "  (conv3): GraphConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 170/170 [00:07<00:00, 22.36epoch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "0.9428571428571428\n",
            "0.8541666666666666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = MyModel(hidden_channels=64,\n",
        "                conv1=GraphConv(dataset.num_node_features, 64),\n",
        "                conv2=GraphConv(64, 64),\n",
        "                conv3=GraphConv(64, 64))\n",
        "print(model)\n",
        "\n",
        "handler = ModelHandler(model, 170)\n",
        "\n",
        "handler.train(train_loader)\n",
        "print('\\n')\n",
        "print(handler.test(train_loader))\n",
        "print(handler.test(test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Henv4bohx-RK"
      },
      "source": [
        "## Using GAT Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QBVmHfgWx3du",
        "outputId": "cbbd09af-972c-4230-bac5-ca655b118642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MyModel(\n",
            "  (conv1): GAT(7, 64, num_layers=3)\n",
            "  (conv2): GAT(64, 64, num_layers=3)\n",
            "  (conv3): GAT(64, 64, num_layers=3)\n",
            "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 170/170 [00:25<00:00,  6.66epoch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "0.8142857142857143\n",
            "0.7083333333333334\n"
          ]
        }
      ],
      "source": [
        "model = MyModel(hidden_channels=64,\n",
        "                conv1=GAT(dataset.num_node_features, 64, 3),\n",
        "                conv2=GAT(64, 64, 3),\n",
        "                conv3=GAT(64, 64, 3))\n",
        "print(model)\n",
        "\n",
        "handler = ModelHandler(model, 170)\n",
        "\n",
        "handler.train(train_loader)\n",
        "print('\\n')\n",
        "print(handler.test(train_loader))\n",
        "print(handler.test(test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpE4C9k3yaRh"
      },
      "source": [
        "## Minibatch\n",
        "we can construct an ego-network for each node in the graph and use this ego-network as the subgraph. This sampling procedure is similar to the neighbourhood sampling method proposed by Hamilton et al. (2017a). Given a node v ∈ V, its ego-network of depth d is the induced subgraph obtained from a sample of all nodes with a distance of at most d to v. Sampling is done at each level, with replacement of a fixed amount of neighbours. This is to make the subgraphs to have equal size. To create a batch of size b, we create b such ego-networks."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qUjKT3GCzrqO",
        "xc3ig2UNzehq",
        "PfyUnZDSxYYr",
        "O8S95UkaxeH7",
        "Henv4bohx-RK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
