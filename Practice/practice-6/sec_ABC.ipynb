{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "11ff76eb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import KarateClub\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "c2f7fbe9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 4., 5., ..., 2., 0., 0.],\n",
       "       [4., 0., 6., ..., 0., 0., 0.],\n",
       "       [5., 6., 0., ..., 0., 2., 0.],\n",
       "       ...,\n",
       "       [2., 0., 0., ..., 0., 4., 4.],\n",
       "       [0., 0., 2., ..., 4., 0., 5.],\n",
       "       [0., 0., 0., ..., 4., 5., 0.]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = nx.karate_club_graph()\n",
    "X = nx.to_numpy_array(graph)\n",
    "position = nx.spring_layout(graph, seed=55)\n",
    "N = len(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "2ad01df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34,)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i in graph.nodes:\n",
    "    club_names = graph.nodes[i]['club']\n",
    "    labels.append(1 if club_names== 'Officer' else 0)\n",
    "Y = np.array(labels)\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.LongTensor(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "02a4d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "184d4366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for training and testing sets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "ad50648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KarateClubClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(KarateClubClassifier, self).__init__()\n",
    "        self.layers = []\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            if i == 0:\n",
    "                self.layers.append(nn.Linear(input_size, hidden_size))\n",
    "            else:\n",
    "                self.layers.append(nn.Linear(hidden_sizes[i-1], hidden_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "8b1b9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[1]\n",
    "layer_result = []\n",
    "\n",
    "def layer_run(layer_size):\n",
    "    hidden_sizes = [64 for i in range(layer_size)] \n",
    "    output_size = 2\n",
    "    model = KarateClubClassifier(input_size, hidden_sizes, output_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(70):\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('layer_size: {} , Accuracy:  {} %'.format(layer_size,100 * correct / total))\n",
    "    layer_result.append(100 * correct / total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section A&B: 2-20 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_size: 1 , Accuracy:  100.0 %\n",
      "layer_size: 2 , Accuracy:  100.0 %\n",
      "layer_size: 3 , Accuracy:  100.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_size: 4 , Accuracy:  100.0 %\n",
      "layer_size: 5 , Accuracy:  100.0 %\n",
      "layer_size: 6 , Accuracy:  100.0 %\n",
      "layer_size: 7 , Accuracy:  100.0 %\n",
      "layer_size: 8 , Accuracy:  71.42857142857143 %\n",
      "layer_size: 9 , Accuracy:  100.0 %\n",
      "layer_size: 10 , Accuracy:  100.0 %\n",
      "layer_size: 11 , Accuracy:  100.0 %\n",
      "layer_size: 12 , Accuracy:  57.142857142857146 %\n",
      "layer_size: 13 , Accuracy:  85.71428571428571 %\n",
      "layer_size: 14 , Accuracy:  85.71428571428571 %\n",
      "layer_size: 15 , Accuracy:  28.571428571428573 %\n",
      "layer_size: 16 , Accuracy:  57.142857142857146 %\n",
      "layer_size: 17 , Accuracy:  57.142857142857146 %\n",
      "layer_size: 18 , Accuracy:  42.857142857142854 %\n",
      "layer_size: 19 , Accuracy:  71.42857142857143 %\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 20):\n",
    "    layer_run(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section C:\n",
    "\n",
    "by increasing the number of layers, the accuracy of the model increases. However, the accuracy of the model is not always increasing. For example, when the number of layers is 7, the accuracy of the model is 100, but when the number of layers is 8, the accuracy of the model is 71. This is because the model is overfitting. for high number of layers, the model is overfitting and the accuracy of the model is decreasing and model going to be unstable."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
